{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d13a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>DATA_YEAR</th>\n",
       "      <th>ORI</th>\n",
       "      <th>PUB_AGENCY_NAME</th>\n",
       "      <th>PUB_AGENCY_UNIT</th>\n",
       "      <th>AGENCY_TYPE_NAME</th>\n",
       "      <th>STATE_ABBR</th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>DIVISION_NAME</th>\n",
       "      <th>REGION_NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>OFFENDER_RACE</th>\n",
       "      <th>OFFENDER_ETHNICITY</th>\n",
       "      <th>VICTIM_COUNT</th>\n",
       "      <th>OFFENSE_NAME</th>\n",
       "      <th>TOTAL_INDIVIDUAL_VICTIMS</th>\n",
       "      <th>LOCATION_NAME</th>\n",
       "      <th>BIAS_DESC</th>\n",
       "      <th>VICTIM_TYPES</th>\n",
       "      <th>MULTIPLE_OFFENSE</th>\n",
       "      <th>MULTIPLE_BIAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3015</td>\n",
       "      <td>1991</td>\n",
       "      <td>AR0040200</td>\n",
       "      <td>Rogers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Intimidation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Highway/Road/Alley/Street/Sidewalk</td>\n",
       "      <td>Anti-Black or African American</td>\n",
       "      <td>Individual</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3016</td>\n",
       "      <td>1991</td>\n",
       "      <td>AR0290100</td>\n",
       "      <td>Hope</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Highway/Road/Alley/Street/Sidewalk</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>1991</td>\n",
       "      <td>AR0350100</td>\n",
       "      <td>Pine Bluff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Residence/Home</td>\n",
       "      <td>Anti-Black or African American</td>\n",
       "      <td>Individual</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1991</td>\n",
       "      <td>AR0350100</td>\n",
       "      <td>Pine Bluff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Aggravated Assault;Destruction/Damage/Vandalis...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Highway/Road/Alley/Street/Sidewalk</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3017</td>\n",
       "      <td>1991</td>\n",
       "      <td>AR0350100</td>\n",
       "      <td>Pine Bluff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Service/Gas Station</td>\n",
       "      <td>Anti-White</td>\n",
       "      <td>Individual</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   INCIDENT_ID  DATA_YEAR        ORI PUB_AGENCY_NAME PUB_AGENCY_UNIT  \\\n",
       "0         3015       1991  AR0040200          Rogers             NaN   \n",
       "1         3016       1991  AR0290100            Hope             NaN   \n",
       "2           43       1991  AR0350100      Pine Bluff             NaN   \n",
       "3           44       1991  AR0350100      Pine Bluff             NaN   \n",
       "4         3017       1991  AR0350100      Pine Bluff             NaN   \n",
       "\n",
       "  AGENCY_TYPE_NAME STATE_ABBR STATE_NAME       DIVISION_NAME REGION_NAME  ...  \\\n",
       "0             City         AR   Arkansas  West South Central       South  ...   \n",
       "1             City         AR   Arkansas  West South Central       South  ...   \n",
       "2             City         AR   Arkansas  West South Central       South  ...   \n",
       "3             City         AR   Arkansas  West South Central       South  ...   \n",
       "4             City         AR   Arkansas  West South Central       South  ...   \n",
       "\n",
       "               OFFENDER_RACE OFFENDER_ETHNICITY VICTIM_COUNT  \\\n",
       "0                      White                NaN            1   \n",
       "1  Black or African American                NaN            1   \n",
       "2  Black or African American                NaN            1   \n",
       "3  Black or African American                NaN            2   \n",
       "4  Black or African American                NaN            1   \n",
       "\n",
       "                                        OFFENSE_NAME  \\\n",
       "0                                       Intimidation   \n",
       "1                                     Simple Assault   \n",
       "2                                 Aggravated Assault   \n",
       "3  Aggravated Assault;Destruction/Damage/Vandalis...   \n",
       "4                                 Aggravated Assault   \n",
       "\n",
       "   TOTAL_INDIVIDUAL_VICTIMS                       LOCATION_NAME  \\\n",
       "0                       1.0  Highway/Road/Alley/Street/Sidewalk   \n",
       "1                       1.0  Highway/Road/Alley/Street/Sidewalk   \n",
       "2                       1.0                      Residence/Home   \n",
       "3                       1.0  Highway/Road/Alley/Street/Sidewalk   \n",
       "4                       1.0                 Service/Gas Station   \n",
       "\n",
       "                        BIAS_DESC  VICTIM_TYPES MULTIPLE_OFFENSE MULTIPLE_BIAS  \n",
       "0  Anti-Black or African American    Individual                S             S  \n",
       "1                      Anti-White    Individual                S             S  \n",
       "2  Anti-Black or African American    Individual                S             S  \n",
       "3                      Anti-White    Individual                M             S  \n",
       "4                      Anti-White    Individual                S             S  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import API key\n",
    "from api_keys import geoapify_key\n",
    "# Read csv file\n",
    "crime_data_df = pd.read_csv(\"../Resources/hate_crime.csv\", low_memory=False)\n",
    "# Define a function to be used later for making bar charts\n",
    "def make_bar():\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    color = mpl.cm.cool(np.linspace(.1, 1, 31))\n",
    "    plt.rcParams['axes.facecolor'] = 'lightcyan'\n",
    "    plt.bar(x, y, align='center',hatch=h,color=color, edgecolor=\"black\", width= .5, linewidth=2.5)\n",
    "    \n",
    "    plt.xticks(x, rotation='vertical')\n",
    "    plt.title(title, fontsize = 17)\n",
    "    plt.xlabel(xl, fontsize = 17)\n",
    "    plt.ylabel(yl, fontsize = 17) \n",
    " \n",
    "# Define a function to be used later for making pie charts\n",
    "def make_pie():\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('lightcyan')\n",
    "    global e\n",
    "    labels = x.index.values \n",
    "  \n",
    "    colors = ['#33F6FF','#33A5FF','#8033FF','#C733FF','#F633FF']\n",
    "   \n",
    "    wp = { 'linewidth' : 1, 'edgecolor' : \"black\"}  \n",
    "    \n",
    "    plt.pie(x, labels=labels, colors=colors,wedgeprops = wp, explode=e, \\\n",
    "        autopct='%1.1f%%',pctdistance=0.79,startangle=90,shadow=True, radius=1.8 *1000,labeldistance=1.05)\n",
    "    plt.title(title, fontsize = 17)\n",
    "    plt.axis('equal')\n",
    "    plt.legend(legend, loc=\"lower left\",facecolor='white', framealpha=1)\n",
    "    plt.tight_layout()   \n",
    "# Define a function to reindex the months in order from Jan - Dec\n",
    "def rdex1():\n",
    "    global recount1\n",
    "    recount1 = counts.reindex(index=[\"JAN\",'FEB','MAR', 'APR','MAY','JUN','JUL','AUG', 'SEP','OCT','NOV','DEC'])\n",
    "\n",
    "# Define a function to reindex the days in order from 1 - 31\n",
    "def rdex2():\n",
    "    global recount2\n",
    "    recount2 = counts.reindex(index=[\"01\",'02','03', '04','05','06','07','08', '09','10','11','12',\"13\",'14','15',\\\n",
    "                                '16','17','18','19','20', '21','22','23','24','25','26','27','28','29','30','31'])\n",
    " def api_query():   \n",
    "    # Gathering LAT and LNG for each state to use in map\n",
    "    state_unique = peak_year[\"STATE_NAME\"].unique()\n",
    "    city_overall = top_5_overall.index.values\n",
    "    city_2001 = top_5_2001.index.values\n",
    "\n",
    "    # Set the API base URL\n",
    "    url = \"https://api.geoapify.com/v1/geocode/search?country=United%20States%20of%20America\"\n",
    "\n",
    "    # Define empty lists for the data of each state and desired cities,set them to global\n",
    "    # to be used outside of the function, and added record counter\n",
    "    global state_data\n",
    "    global city_overall_data\n",
    "    global city_2001_data\n",
    "    \n",
    "    state_data = []\n",
    "    city_overall_data = []\n",
    "    city_2001_data = []\n",
    "    rcnt = 1\n",
    "\n",
    "    # Print to logger\n",
    "    print(\"Beginning State Data Retrieval     \")\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "    # Loop through all the cities in our list to fetch location data\n",
    "    for state in state_unique:\n",
    "\n",
    "        # Create endpoint URL with each city\n",
    "        state_url = url + \"&state=\"+ state + \"&apiKey=\" + geoapify_key\n",
    "\n",
    "    #     print(f\"Processing Record{rcnt} for {state}\")\n",
    "    #     rcnt += 1\n",
    "        # Run an API request for each of the cities\n",
    "        try:\n",
    "            # Parse the JSON and retrieve data\n",
    "            state_info = requests.get(state_url).json()\n",
    "\n",
    "            # Parse out latitude, longitude\n",
    "            state_lat = state_info[\"features\"][0][\"properties\"][\"lat\"]\n",
    "            state_lng = state_info[\"features\"][0][\"properties\"][\"lon\"]\n",
    "\n",
    "            # Append the state information into state_data list\n",
    "            state_data.append({\"State\": state, \n",
    "                              \"Lat\": state_lat, \n",
    "                              \"Lng\": state_lng})\n",
    "    # If an error is experienced, skip the city\n",
    "        except:\n",
    "            pass\n",
    "            print(\"you screwed up somewhere\")\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"State Data Retrieval Complete\\nBeginning Overall City Data Retrieval\")\n",
    "    print(\"-----------------------------\")\n",
    "    rcnt = 1\n",
    "\n",
    "    for city in city_overall:\n",
    "\n",
    "\n",
    "        # Create endpoint URL with each city\n",
    "        city_url = url + \"&city=\"+ city + \"&apiKey=\" + geoapify_key\n",
    "\n",
    "        print(f\"Processing Record {rcnt} for {city}\")\n",
    "        rcnt += 1\n",
    "        # Run an API request for each of the cities\n",
    "        try:\n",
    "            # Parse the JSON and retrieve data\n",
    "            city_info = requests.get(city_url).json()\n",
    "\n",
    "            # Parse out latitude, longitude\n",
    "            city_lat = city_info[\"features\"][0][\"properties\"][\"lat\"]\n",
    "            city_lng = city_info[\"features\"][0][\"properties\"][\"lon\"]\n",
    "\n",
    "            # Append the state information into state_data list\n",
    "            city_overall_data.append({\n",
    "                              \"City\": city, \n",
    "                              \"Lat\": city_lat, \n",
    "                              \"Lng\": city_lng})\n",
    "    # If an error is experienced, skip the city\n",
    "        except:\n",
    "            pass\n",
    "            print(\"you screwed up somewhere\")\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Overall City Data Retrieval Complete\\nBeginning 2001 City Data Retrieval\")\n",
    "    print(\"-----------------------------\")\n",
    "    rcnt = 1\n",
    "\n",
    "    for city in city_2001:\n",
    "\n",
    "\n",
    "        # Create endpoint URL with each city\n",
    "        city_url = url + \"&city=\"+ city + \"&apiKey=\" + geoapify_key\n",
    "\n",
    "        print(f\"Processing Record {rcnt} for {city}\")\n",
    "        rcnt += 1\n",
    "        # Run an API request for each of the cities\n",
    "        try:\n",
    "            # Parse the JSON and retrieve data\n",
    "            city_info = requests.get(city_url).json()\n",
    "\n",
    "            # Parse out latitude, longitude\n",
    "            city_lat = city_info[\"features\"][0][\"properties\"][\"lat\"]\n",
    "            city_lng = city_info[\"features\"][0][\"properties\"][\"lon\"]\n",
    "\n",
    "            # Append the state information into state_data list\n",
    "            city_2001_data.append({\n",
    "                              \"City\": city, \n",
    "                              \"Lat\": city_lat, \n",
    "                              \"Lng\": city_lng})\n",
    "    # If an error is experienced, skip the city\n",
    "        except:\n",
    "            pass\n",
    "            print(\"you screwed up somewhere\")\n",
    "\n",
    "    # Indicate that Data Loading is complete \n",
    "    print(\"-----------------------------\")\n",
    "    print(\"2001 City Data Retrieval Complete\")\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Your Geoapify Requests Are Complete\")\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "\n",
    "# GROUP 3 PROJECT\n",
    "\n",
    "\n",
    "### For this project, will be looking at the FBI Hate Crimes dataset from 1991 to 2018. We will look at the raw data and remove anything that could skew our results that we hope to find. We will determine the offense that occurs the most throughout the 28 year span, then compare it to the top 5 cities with the most hate crime incidents. We also will determine which year had the most offenses and compare the same offense to the top 5 cities of the peak crime year. We want to compare the bias description (targeted group) to the offender race and compare that to the offense type. We will plot the most common crimes and use that to compare over the years. By the end of our analysis, we will find out which state and city within that state which has the highest hate crime. \n",
    "\n",
    "# Display the dataframe\n",
    "crime_data_df.head(3)\n",
    "# Clean up the data\n",
    "# Drop columns of data not needed\n",
    "clean_crime = crime_data_df.drop(columns=[\"ORI\", \"PUB_AGENCY_UNIT\", \"JUVENILE_VICTIM_COUNT\",\"ADULT_VICTIM_COUNT\", \"ADULT_OFFENDER_COUNT\", 'JUVENILE_OFFENDER_COUNT', \"POPULATION_GROUP_CODE\", \"POPULATION_GROUP_DESC\", \"LOCATION_NAME\", \"DIVISION_NAME\"])\n",
    "\n",
    "# Dropping \"Guam\", \"Federal\", \"District of Columbia\" from clean_crime to keep only the named continental states\n",
    "state_drop = [\"Guam\", \"Federal\", \"District of Columbia\"]\n",
    "clean_crime = clean_crime[~clean_crime[\"STATE_NAME\"].isin(state_drop)]\n",
    "\n",
    "#Split Ofense names into main and sub categories to only look at the main offense\n",
    "clean_crime[[\"MAIN_OFFENSE\",\"SUB_OFFENSE\"]] = clean_crime[\"OFFENSE_NAME\"].str.split('/', n=1, expand= True)\n",
    "clean_crime[\"MAIN_OFFENSE\"] = clean_crime[\"MAIN_OFFENSE\"].str.split(';', n=1, expand= True)\n",
    "\n",
    "# Split the incident date into year,month, and day\n",
    "dates = clean_crime['INCIDENT_DATE'].str.split(\"-\", n = 2, expand = True) \n",
    "\n",
    "# Add new columns to the cleaned dataframe and droped the original date column\n",
    "clean_crime[\"DAY\"]= dates[0]\n",
    "clean_crime[\"MONTH\"]= dates[1]\n",
    "clean_crime[\"LAT\"] = \"\"\n",
    "clean_crime[\"LNG\"] = \"\"\n",
    "clean_crime.drop(columns =[\"INCIDENT_DATE\"], inplace = True)\n",
    "\n",
    "# Rename the year column and replace offender race to only the main category and change the order of the columns to have all 3 date columns together\n",
    "clean_crime.rename(columns={'DATA_YEAR': 'YEAR'}, inplace=True)\n",
    "clean_crime['OFFENDER_RACE'] = clean_crime['OFFENDER_RACE'].replace(['American Indian or Alaska Native', 'Asian' , 'Native Hawaiian or Other Pacific Islander'],'AAPI').copy()\n",
    "clean_crime= clean_crime[['STATE_NAME','STATE_ABBR','PUB_AGENCY_NAME','LAT','LNG','YEAR',\"MONTH\",\"DAY\",'MAIN_OFFENSE','BIAS_DESC','OFFENDER_RACE','VICTIM_COUNT']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#display new dataframe\n",
    "# clean_crime\n",
    "# Make a pie chart showing the top 5 most occuring crimes\n",
    "crime_type = clean_crime['MAIN_OFFENSE'].value_counts().nlargest(5)\n",
    "x = crime_type\n",
    "labels = None\n",
    "legend = crime_type.index.values\n",
    "title= (\"Most Common Offense\")\n",
    "e = (100, 30, 30, 30, 30)\n",
    "make_pie()\n",
    "\n",
    "#save to Output folder\n",
    "plt.savefig(\"../Output/Fig11.jpeg\")\n",
    "\n",
    "#Display the chart\n",
    "plt.show()\n",
    "# Which hate crime most prevalent?\n",
    "# Getting the counts of the 5 most prevalent ofense types\n",
    "offense_info= clean_crime['MAIN_OFFENSE'].value_counts().nlargest(n=5)\n",
    "offense_info\n",
    "# Getting the counts of the most prevalent offender types\n",
    "offender_info= clean_crime['OFFENDER_RACE'].value_counts().nlargest(n=5)\n",
    "offender_info\n",
    "# What bias description (targeted group) is most susceptible?\n",
    "# Getting the counts of the most prevalent Bias Description\n",
    "bias_info = clean_crime['BIAS_DESC'].value_counts().nlargest(n=5)\n",
    "bias_info\n",
    "# Show the counts of the most prevalent Bias Description in a bar chart \n",
    "x = bias_info.index.values\n",
    "y = bias_info.values\n",
    "h = ''\n",
    "title=\"Bias Description of the victims\\nof Hate Crimes over 28 Years\"\n",
    "xl = 'Bias Description'\n",
    "yl = 'Number of Hate Crimes in The US'\n",
    "legend = bias_info.index\n",
    "make_bar()\n",
    "\n",
    "#save to Output folder\n",
    "plt.savefig(\"../Output/Fig8.jpeg\")\n",
    "\n",
    "#Display the chart\n",
    "plt.show()\n",
    "# Graph a nested pie chart showing the offenders off the top bias description\n",
    "# Rename Dataframe to include only the needed columns\n",
    "off_bias_df = clean_crime[clean_crime['BIAS_DESC'] == \"Anti-Black or African American\" ]\n",
    "pie_df = off_bias_df[['BIAS_DESC', 'OFFENDER_RACE','VICTIM_COUNT',]]\n",
    "\n",
    "# Set inner and outer counts and labels\n",
    "outer = pie_df.groupby('OFFENDER_RACE').sum()\n",
    "outer.index\n",
    "\n",
    "inner = pie_df.groupby(['BIAS_DESC',]).sum()\n",
    "inner_labels = inner.index.get_level_values(0)\n",
    "\n",
    "# Set parameters and plots\n",
    "fig, ax = plt.subplots(figsize=(24,12))\n",
    "size = 0.3\n",
    "\n",
    "fig.patch.set_facecolor('lightcyan')\n",
    "colors = ['#F633FF','#8033FF','#33F6FF','#C733FF','#33A5FF']\n",
    "ax.pie(outer.values.flatten(), radius=1,\n",
    "       labels=outer.index.values,\n",
    "       colors = ['#33F6FF','#33A5FF','#8033FF','#C733FF','#F633FF'],\n",
    "       autopct='%1.1f%%',\n",
    "       pctdistance=0.79,\n",
    "       wedgeprops=dict(width=size, edgecolor='w'))\n",
    "\n",
    "ax.pie(inner.values.flatten(), radius=1-size, \n",
    "       labels = inner_labels,\n",
    "       colors = ['#2eaeb3'],\n",
    "       labeldistance= .1,\n",
    "       wedgeprops=dict(width=size, edgecolor='w'))\n",
    "\n",
    "# Add title and legend\n",
    "ax.set(aspect=\"equal\", title='Offender Totals for the most Suseptible\\nBias Description (Anti-Black or African American)', )\n",
    "legend = outer.index.values\n",
    "plt.legend(legend, loc=\"upper left\",facecolor='white', framealpha=1)\n",
    "\n",
    "#save to Output folder\n",
    "plt.savefig(\"../Output/Fig12.jpeg\")\n",
    "\n",
    "#Display the chart\n",
    "plt.show()\n",
    "# What year has the most crimes throughout the years?\n",
    "# Get the count of offenses for each year and plot a bar chart \n",
    "year_counts = clean_crime['YEAR'].value_counts()\n",
    "x = year_counts.index.values\n",
    "y = year_counts.values\n",
    "h = ''\n",
    "title=\"Hate Crime Counts Over 28 Years\"\n",
    "xl = 'Year'\n",
    "yl = 'Number of Hate Crimes in The US'\n",
    "make_bar()\n",
    "\n",
    "#save to Output folder\n",
    "plt.savefig(\"../Output/Fig1.jpeg\")\n",
    "\n",
    "#Display the chart\n",
    "plt.show()\n",
    "# Which city/state has most hate crime(s)?\n",
    "# Get the count of offenses for the peak year and plot a bar chart \n",
    "peak_year = clean_crime[clean_crime['YEAR'] == 2001]\n",
    "states = peak_year['STATE_NAME'].value_counts().nlargest(15)\n",
    "x = states.index.values\n",
    "y = states.values\n",
    "h = ''\n",
    "title = \"Peak Year Hate Crimes by The Top 15\\n States With The Most Hate Crimes\"\n",
    "xl = '2001'\n",
    "yl = 'Number of Hate Crimes'\n",
    "make_bar()\n",
    "\n",
    "# Save to Output folder\n",
    "plt.savefig(\"../Output/Fig2.jpeg\")\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "# Plot a line chart showing the hate crime trend during the peak crime year\n",
    "peak_year_df = peak_year['MONTH'].value_counts()\n",
    "\n",
    "# Reorganize the index\n",
    "rdex = peak_year_df.reindex(index=[\"JAN\",'FEB','MAR', 'APR','MAY','JUN','JUL','AUG', 'SEP','OCT','NOV','DEC'])\n",
    "x= rdex.index.values\n",
    "y= rdex.values\n",
    "plt.rcParams['figure.figsize'] = [15, 8]\n",
    "plt.plot(x, y, marker='x')\n",
    "plt.xlabel(\"Month\", fontsize=17)\n",
    "plt.ylabel(\"Number of Incidents\", fontsize=17)\n",
    "plt.title(\"Number of Hate Crimes in 2001 by Month\", fontsize=17)\n",
    "plt.xticks(x)\n",
    "\n",
    "# Save to Output folder\n",
    "plt.savefig(\"../Output/Fig9.jpeg\")\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "# Plot a line chart showing the hate crime trend during the peak crime month\n",
    "peak_day = peak_year[peak_year['MONTH'] == 'SEP']\n",
    "peak_day_df = peak_day['DAY'].value_counts()\n",
    "\n",
    "# Reorganize the index\n",
    "ddex = peak_day_df.reindex(index=[\"01\",'02','03', '04','05','06','07','08', '09','10','11','12',\"13\",'14','15',\\\n",
    "                                '16','17','18','19','20', '21','22','23','24','25','26','27','28','29','30','31'])\n",
    "z = ddex.index.values\n",
    "h =ddex.values\n",
    "plt.plot(z,h, marker=\"o\")\n",
    "plt.ylabel(\"Number of Incidents\")\n",
    "plt.title(\"Number of Hate Crimes in 2001 by day in September\", fontsize=17)\n",
    "plt.xlabel(\"Day\", fontsize=17)\n",
    "plt.ylabel(\"Number of Incidents\", fontsize=17)\n",
    "plt.xticks(z)\n",
    "\n",
    "# Save to Output folder\n",
    "plt.savefig(\"../Output/Fig10.jpeg\")\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "# Get the count of offenses for the state in the peak year with the most offenses \n",
    "max_state_df = peak_year[peak_year['STATE_NAME'] == \"California\"]\n",
    "bias = max_state_df['BIAS_DESC'].value_counts()\n",
    "# bias\n",
    "# Plot a bar chart for the state with the most offenses using the defined function\n",
    "x = bias.index.values\n",
    "y = bias.values\n",
    "h = ''\n",
    "title = \"Across California 2001\"\n",
    "xl = 'Bias Description'\n",
    "yl = 'Count of Offenses'\n",
    "make_bar()\n",
    "\n",
    "# Save to Output folder\n",
    "plt.savefig(\"../Output/Fig3.jpeg\")\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "# Plot a bar chart for the state with the most offenses broken down by month using the defined function\n",
    "counts = max_state_df['MONTH'].value_counts()\n",
    "rdex1()\n",
    "x = recount1.index.values\n",
    "y = recount1.values\n",
    "title = \"California 2001\"\n",
    "xl = 'Month'\n",
    "yl = 'Offense Counts'\n",
    "h = \"\"\n",
    "make_bar()\n",
    "\n",
    "# Save to Output folder\n",
    "plt.savefig(\"../Output/Fig4.jpeg\")\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "# Plot a bar chart for the days in September using the defined function and reset the index chronologically\n",
    "counts = max_state_df['DAY'].value_counts()\n",
    "rdex2()\n",
    "x = recount2.index.values\n",
    "y = recount2.values\n",
    "title  = 'September California 2001'\n",
    "xl ='Day in September'\n",
    "yl = 'September Hate Crime Count'\n",
    "h = \"\"\n",
    "make_bar()\n",
    "\n",
    "# Save to Output folder\n",
    "plt.savefig(\"../Output/Fig5.jpeg\")\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "# Collect the data for the top 5 cities with the most hate crimes over the span of 28 years\n",
    "cities_overall = clean_crime['PUB_AGENCY_NAME'].value_counts().nlargest(n=5)\n",
    "\n",
    "# Change the collected data into a dataframe and rename the column name\n",
    "top_5_overall = pd.DataFrame(cities_overall)\n",
    "top_5_overall = top_5_overall.rename(columns={'PUB_AGENCY_NAME': 'OFFENSE_COUNT'})\n",
    "\n",
    "# Collect the data for the top 5 cities with the most hate crimes in the peak year of 2001\n",
    "cities_year = peak_year['PUB_AGENCY_NAME'].value_counts().nlargest(n=5)\n",
    "\n",
    "# Change the collected data into a dataframe and rename the column name\n",
    "top_5_2001 = pd.DataFrame(cities_year)\n",
    "top_5_2001 = top_5_2001.rename(columns={'PUB_AGENCY_NAME': 'OFFENSE_COUNT'})\n",
    "# using a function, get the Lat and Lon of the states and cities in question\n",
    "api_query()\n",
    "# Display top 5 cities across the years with the most hate crimes\n",
    "top_5_overall\n",
    "# Display top 5 cities across 2001 with the most hate crimes\n",
    "top_5_2001\n",
    "# Display appended data\n",
    "city_2001_data\n",
    "# Change the appended data into a dataframe and add the offense counts\n",
    "city_data_01 = pd.DataFrame(city_2001_data)\n",
    "city_data_01['OFFENSE_COUNT']= top_5_2001[\"OFFENSE_COUNT\"].values\n",
    "city_data_01\n",
    "# Display appended data\n",
    "city_overall_data\n",
    "# Change the appended data into a dataframe and add the offense counts\n",
    "city_data_all = pd.DataFrame(city_overall_data)\n",
    "city_data_all['OFFENSE_COUNT']= top_5_overall[\"OFFENSE_COUNT\"].values\n",
    "city_data_all\n",
    "# Display appended data\n",
    "state_data\n",
    "# Change the appended data into a dataframe \n",
    "state_data_df = pd.DataFrame(state_data)\n",
    "state_data_df.head()\n",
    "\n",
    "# Configure the map plot for the top 5 cities over all\n",
    "map_it = city_data_all.hvplot.points(\n",
    "    \"Lng\",\n",
    "    \"Lat\",\n",
    "    geo = True,\n",
    "    tiles = \"EsriNatGeo\",\n",
    "    size = 3000,\n",
    "    color = \"#F633FF\",\n",
    "    alpha = 0.75,\n",
    "    colorbar=True,\n",
    "    hover_cols = \"\",\n",
    "    \n",
    "   \n",
    "    )\n",
    "\n",
    "# city name, offense count\n",
    "# Display the map\n",
    "map_it\n",
    "# Showing the top 5 cities across 28 years that have the most hate crimes\n",
    "x = cities_overall\n",
    "e = (50, 30, 30, 30, 30)\n",
    "title = \"Top 5 Cities from 1991 to 2018\\n With the Most Hate Crimes\"\n",
    "legend = cities_overall.index.values\n",
    "make_pie()\n",
    "\n",
    "# Save to Output folder\n",
    "plt.savefig(\"../Output/Fig6.jpeg\")\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "# Configure the map plot for the top 5 cities in 2001\n",
    "map_it = city_data_01.hvplot.points(\n",
    "    \"Lng\",\n",
    "    \"Lat\",\n",
    "    geo = True,\n",
    "    tiles = \"EsriNatGeo\",\n",
    "    size = 3000,\n",
    "    color = \"#33F6FF\",\n",
    "    alpha = 0.75,\n",
    "   \n",
    "    )\n",
    "\n",
    "# Display the map\n",
    "map_it\n",
    "\n",
    "# Showing the top 5 cities in 2001 that have the most hate crimes\n",
    "x = cities_year\n",
    "e = (100, 30, 30, 30, 30)\n",
    "title = \"Top 5 Cities in 2001\\n With the Most Hate Crimes\"\n",
    "make_pie()\n",
    "\n",
    "# Save to Output folder\n",
    "plt.savefig(\"../Output/Fig7.jpeg\")\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a00427395dc9113929f7b766d6bc1fd0935f9df126b09ba5b7202b0db8113df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
